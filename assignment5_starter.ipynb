{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the KNN class\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store the training data.\"\"\"\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for the given input samples.\"\"\"\n",
    "        X = np.array(X)\n",
    "        predictions = [self._predict_single(x) for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict the probabilities for each class.\"\"\"\n",
    "        X = np.array(X)\n",
    "        prob_predictions = [self._predict_proba_single(x) for x in X]\n",
    "        return np.array(prob_predictions)\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"Predict the label for a single input sample.\"\"\"\n",
    "        distances = self._compute_distances(x)\n",
    "        nearest_indices = np.argsort(distances)[:self.k]\n",
    "        nearest_labels = self.y_train[nearest_indices]\n",
    "        most_common = Counter(nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def _predict_proba_single(self, x):\n",
    "        \"\"\"Predict the probability for a single input sample.\"\"\"\n",
    "        distances = self._compute_distances(x)\n",
    "        nearest_indices = np.argsort(distances)[:self.k]\n",
    "        nearest_labels = self.y_train[nearest_indices]\n",
    "        count = Counter(nearest_labels)\n",
    "        # Return probabilities for each class\n",
    "        return [count.get(0, 0) / self.k, count.get(1, 0) / self.k]\n",
    "\n",
    "    def _compute_distances(self, x):\n",
    "        \"\"\"Compute the distances from a single point to all training data points.\"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.linalg.norm(self.X_train - x, axis=1)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(self.X_train - x), axis=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported distance metric: {self.distance_metric}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define data preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    # Load datasets\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = train_data.drop(['Exited', 'id', 'CustomerID', 'Surname'], axis=1, errors='ignore')\n",
    "    y = train_data['Exited']  # Target variable\n",
    "    X_test = test_data.drop(['id', 'CustomerID'], axis=1, errors='ignore')\n",
    "\n",
    "    # One-hot encode character variables with fewer than 5 unique values\n",
    "    cat_columns = X.select_dtypes(include=['object']).columns\n",
    "    small_cat_columns = [col for col in cat_columns if X[col].nunique() < 5]\n",
    "\n",
    "    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    X_encoded = encoder.fit_transform(X[small_cat_columns])\n",
    "    X_test_encoded = encoder.transform(X_test[small_cat_columns])\n",
    "\n",
    "    # Create DataFrames from encoded data\n",
    "    X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(small_cat_columns))\n",
    "    X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(small_cat_columns))\n",
    "\n",
    "    # Drop original categorical columns\n",
    "    X = X.drop(small_cat_columns, axis=1)\n",
    "    X_test = X_test.drop(small_cat_columns, axis=1)\n",
    "\n",
    "    # Concatenate encoded columns with original data\n",
    "    X = pd.concat([X, X_encoded_df], axis=1)\n",
    "    X_test = pd.concat([X_test, X_test_encoded_df], axis=1)\n",
    "\n",
    "    # **Fix the KeyError here**: Make sure both X and X_test have the same columns\n",
    "    X_test = X_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "    # Scale numeric columns\n",
    "    numeric_columns = ['Balance', 'EstimatedSalary', 'Age', 'CreditScore']\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_columns] = scaler.fit_transform(X[numeric_columns])\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "    # Handle missing values for numeric and categorical columns separately\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype in ['int64', 'float64']:\n",
    "            X[col].fillna(X[col].mean(), inplace=True)\n",
    "        else:\n",
    "            X[col].fillna(X[col].mode()[0], inplace=True)  # Fill with the mode (most common value)\n",
    "\n",
    "    for col in X_test.columns:\n",
    "        if X_test[col].dtype in ['int64', 'float64']:\n",
    "            X_test[col].fillna(X_test[col].mean(), inplace=True)\n",
    "        else:\n",
    "            X_test[col].fillna(X_test[col].mode()[0], inplace=True)\n",
    "\n",
    "    return X, y, X_test\n",
    "\n",
    "# Usage example:\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation function\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    # TODO: Implement cross-validation\n",
    "    # Compute ROC AUC scores\n",
    "    # Ensure input is in NumPy format\n",
    "    X = X.to_numpy() if isinstance(X, pd.DataFrame) else X\n",
    "    y = y.to_numpy() if isinstance(y, pd.Series) else y\n",
    "    \n",
    "    \"\"\"Perform cross-validation and compute ROC AUC scores.\"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Train the KNN model on the current fold\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        # Compute ROC AUC score for the current fold\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    # Return the average ROC AUC score across all folds\n",
    "    return np.mean(roc_auc_scores)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Cross-Validation with .iloc fix for pandas DataFrame\n",
    "def manual_cross_validate(X, y, knn, n_splits=5):\n",
    "    \"\"\"Manually perform cross-validation and compute ROC AUC scores.\"\"\"\n",
    "    n_samples = len(X)\n",
    "    fold_size = n_samples // n_splits\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for fold in range(n_splits):\n",
    "        start = fold * fold_size\n",
    "        end = (fold + 1) * fold_size if fold != n_splits - 1 else n_samples\n",
    "        test_indices = indices[start:end]\n",
    "        train_indices = np.concatenate((indices[:start], indices[end:]))\n",
    "\n",
    "        # Use .iloc to access rows by positional indices\n",
    "        X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "        y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "\n",
    "        # Train KNN on the training fold\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Get probabilities for ROC calculation\n",
    "        y_proba = knn.predict_proba(X_test)[:, 1]  # Get the probability for class 1\n",
    "\n",
    "        # Manually compute ROC AUC for the current fold\n",
    "        roc_auc = compute_manual_roc_auc(y_test, y_proba)\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    return np.mean(roc_auc_scores)\n",
    "\n",
    "\n",
    "# Manual ROC and AUC Computation\n",
    "def compute_manual_roc_auc(y_true, y_scores):\n",
    "    \"\"\"Manually compute ROC AUC score.\"\"\"\n",
    "    thresholds = np.linspace(0, 1, 100)  # 100 thresholds from 0 to 1\n",
    "    tpr_list = []  # True Positive Rate\n",
    "    fpr_list = []  # False Positive Rate\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # Apply the threshold to make binary predictions\n",
    "        y_pred = (y_scores >= threshold).astype(int)\n",
    "\n",
    "        # Calculate TPR and FPR\n",
    "        tp = np.sum((y_pred == 1) & (y_true == 1))  # True Positives\n",
    "        fp = np.sum((y_pred == 1) & (y_true == 0))  # False Positives\n",
    "        fn = np.sum((y_pred == 0) & (y_true == 1))  # False Negatives\n",
    "        tn = np.sum((y_pred == 0) & (y_true == 0))  # True Negatives\n",
    "\n",
    "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity / Recall\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # Fall-out / 1-Specificity\n",
    "\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "\n",
    "    # Compute AUC using the trapezoidal rule\n",
    "    auc = np.trapz(tpr_list, fpr_list)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation ROC AUC score: -0.5109773284662806\n",
      "k=1, ROC AUC=-0.5076\n",
      "k=2, ROC AUC=-0.5229\n",
      "k=3, ROC AUC=-0.5184\n",
      "k=4, ROC AUC=-0.5115\n",
      "k=5, ROC AUC=-0.5070\n",
      "k=6, ROC AUC=-0.5096\n",
      "k=7, ROC AUC=-0.5078\n",
      "k=8, ROC AUC=-0.5088\n",
      "k=9, ROC AUC=-0.5102\n",
      "k=10, ROC AUC=-0.5065\n",
      "k=11, ROC AUC=-0.5146\n",
      "k=12, ROC AUC=-0.5066\n",
      "k=13, ROC AUC=-0.5103\n",
      "k=14, ROC AUC=-0.5092\n",
      "k=15, ROC AUC=-0.5110\n",
      "k=16, ROC AUC=-0.5081\n",
      "k=17, ROC AUC=-0.5022\n",
      "k=18, ROC AUC=-0.5060\n",
      "k=19, ROC AUC=-0.5048\n",
      "k=20, ROC AUC=-0.5031\n",
      "Best k: None, Best ROC AUC: 0.0000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/of/test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m knn\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Save test predictions\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/path/of/test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExited\u001b[39m\u001b[38;5;124m'\u001b[39m: test_predictions})\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmissions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/of/test.csv'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('/Users/anneke/GitHub/abvo138-assignment-5/train.csv', \n",
    "                               '/Users/anneke/GitHub/abvo138-assignment-5/test.csv')\n",
    "\n",
    "\n",
    "# Create and evaluate model\n",
    "knn = KNN(k=5, distance_metric='euclidean')\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_score = manual_cross_validate(X, y, knn)\n",
    "print(\"Cross-validation ROC AUC score:\", cv_score)\n",
    "\n",
    "# TODO: hyperparamters tuning\n",
    "# Hyperparameter tuning: Find the best k\n",
    "best_k = None\n",
    "best_score = 0\n",
    "\n",
    "for k in range(1, 21):\n",
    "    knn = KNN(k=k, distance_metric='euclidean')\n",
    "    score = manual_cross_validate(X, y, knn)\n",
    "    print(f\"k={k}, ROC AUC={score:.4f}\")\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best k: {best_k}, Best ROC AUC: {best_score:.4f}\")\n",
    "\n",
    "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
    "knn = KNN(k=best_k, distance_metric='euclidean')\n",
    "knn.fit(X, y)\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save test predictions\n",
    "pd.DataFrame({'id': pd.read_csv('/path/of/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 357, in _fit\n    self._validate_steps()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 241, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' '<function preprocess_data at 0x7f7d7cd961f0>' (type <class 'function'>) doesn't\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Perform cross-validation and calculate mean validation AUC score.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Perform 5-fold cross-validation using the cross_val_score function.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# mean_validation_score = TODO\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform 5-fold cross-validation using cross_val_score and calculate mean AUC score\u001b[39;00m\n\u001b[1;32m     26\u001b[0m auc_scorer \u001b[38;5;241m=\u001b[39m make_scorer(roc_auc_score, needs_proba\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 27\u001b[0m cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauc_scorer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m mean_validation_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cv_scores)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Calculate elapsed time and seconds per sample\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m    309\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[0;32m--> 328\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/base.py\", line 1152, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 423, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 357, in _fit\n    self._validate_steps()\n  File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/pipeline.py\", line 241, in _validate_steps\n    raise TypeError(\nTypeError: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' '<function preprocess_data at 0x7f7d7cd961f0>' (type <class 'function'>) doesn't\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7527 with n_neighbors=1\n",
      "Time taken: 22.22 seconds, Seconds per sample: 0.001481 seconds\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################################################\n",
    "# LAB 5 CODE\n",
    "#######################################################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Load train and test CSV files\n",
    "train_data = pd.read_csv('/Users/anneke/GitHub/abvo138-assignment-5/train.csv')\n",
    "test_data = pd.read_csv('/Users/anneke/GitHub/abvo138-assignment-5/test.csv')\n",
    "\n",
    "# Drop id column from the training dataset\n",
    "train_data = train_data.drop(['CustomerId', 'id'], axis=1)\n",
    "\n",
    "# Separate features (X) and target (y) from training data\n",
    "X_train = train_data.drop('Exited', axis=1)\n",
    "y_train = train_data['Exited']\n",
    "\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a Pipeline object that applies the standard scaler to the numerical columns\n",
    "# and the one hot encoder to the categorical columns; then applies the knn classifier (k=5).\n",
    "# The model should match the given output of this cell.\n",
    "# model = TODO\n",
    "# Define the transformations for numerical and categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline that applies the preprocessor and then the KNN classifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors= 5))\n",
    "])\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Define the hyperparameter range for n_neighbors\n",
    "n_neighbors_values = range(1, 21)  # Testing for neighbors from 1 to 20\n",
    "\n",
    "# Store results\n",
    "n_neighbors_list = []\n",
    "auc_scores = []\n",
    "times_per_sample = []\n",
    "\n",
    "# Perform cross-validation over different values of n_neighbors\n",
    "for n_neighbors in n_neighbors_values:\n",
    "    # Same as previous code block.\n",
    "    # model = TODO\n",
    "    model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=n_neighbors))])\n",
    "\n",
    "    # Measure the time taken for cross-validation\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Perform cross-validation and calculate mean validation AUC score.\n",
    "    # Perform 5-fold cross-validation using the cross_val_score function.\n",
    "    # mean_validation_score = TODO\n",
    "    # Perform 5-fold cross-validation using cross_val_score and calculate mean AUC score\n",
    "    auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=auc_scorer)\n",
    "    mean_validation_score = np.mean(cv_scores)\n",
    "\n",
    "    # Calculate elapsed time and seconds per sample\n",
    "    elapsed_time = time.time() - start_time\n",
    "    seconds_per_sample = elapsed_time / len(X_train)\n",
    "\n",
    "    # Store results for plotting\n",
    "    n_neighbors_list.append(n_neighbors)\n",
    "    auc_scores.append(mean_validation_score)\n",
    "    times_per_sample.append(seconds_per_sample)\n",
    "\n",
    "    # Print out the validation accuracy, the value of n_neighbors, and the time per sample\n",
    "    print(f'Validation Accuracy: {mean_validation_score:.4f} with n_neighbors={n_neighbors}')\n",
    "    print(f'Time taken: {elapsed_time:.2f} seconds, Seconds per sample: {seconds_per_sample:.6f} seconds')\n",
    "\n",
    "# Plotting results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Left plot: AUC score vs number of neighbors\n",
    "axs[0].plot(n_neighbors_list, auc_scores, marker='o', linestyle='-', color='b')\n",
    "axs[0].set_xlabel('Number of Neighbors')\n",
    "axs[0].set_ylabel('Validation ROC-AUC Score')\n",
    "axs[0].set_title('Validation ROC-AUC Score vs. Number of Neighbors')\n",
    "\n",
    "# Right plot: Time per sample vs number of neighbors\n",
    "axs[1].plot(n_neighbors_list, times_per_sample, color='r')\n",
    "axs[1].set_xlabel('Number of Neighbors')\n",
    "axs[1].set_ylabel('Time per Sample (seconds)')\n",
    "axs[1].set_title('Time per Sample vs. Number of Neighbors')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Output the best hyperparameter\n",
    "best_n_neighbors = n_neighbors_list[np.argmax(auc_scores)]\n",
    "best_score = np.max(auc_scores)\n",
    "print(f'Best n_neighbors: {best_n_neighbors} with Validation Accuracy: {best_score:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs506",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
